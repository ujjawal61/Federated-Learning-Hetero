{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bzA07dxE61T_"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.models import model_from_json\n",
    "#from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=14 #have to be even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J2KLvpsP64vV"
   },
   "outputs": [],
   "source": [
    "#defining the transformation method\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.Normalize((0.5), (0.5,)),\n",
    "])\n",
    "\n",
    "transform_train_minor = transforms.Compose([\n",
    "    transforms.RandomPerspective(),\n",
    "    transforms.RandomCrop(image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "GUwRg8Cb6-2m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#downloading the dataset\n",
    "# dataset_train = datasets.EMNIST('../data/cifar',split='digits', train=True, download = True, transform = transform)\n",
    "# dataset_test = datasets.EMNIST('../data/cifar-t',split='digits',train=False, download = True, transform = transform)\n",
    "dataset_train = datasets.CIFAR10('../data/cifar', train=True, download = True, transform = transform)\n",
    "dataset_test = datasets.CIFAR10('../data/cifar-t',train=False, download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "-jGKdoxL7Ddd"
   },
   "outputs": [],
   "source": [
    "#this function is sampling the cifar image index in non iid way, each client will have majority of 2 class and 8 minor class\n",
    "def distribute_noniid2(dataset, num_users, p):\n",
    "\n",
    "    idxs = np.arange(len(dataset),dtype=int)\n",
    "    labels = np.array(dataset.targets)\n",
    "    label_list = np.unique(dataset.targets)\n",
    "    \n",
    "    # sort labels\n",
    "    idxs_labels = np.vstack((idxs, labels))\n",
    "    idxs_labels = idxs_labels[:,idxs_labels[1,:].argsort()]\n",
    "    #print(idxs_labels)\n",
    "    idxs = idxs_labels[0,:]\n",
    "    idxs = idxs.astype(int)\n",
    "    n_data=int(len(dataset)/(6*num_users))\n",
    "    dict_users = {i: np.array([], dtype='int64') for i in range(num_users)}\n",
    "\n",
    "    #Sample majority class for each user\n",
    "    user_majority_labels = []\n",
    "    for i in range(num_users):\n",
    "        majority_labels = np.random.choice(label_list, 2, replace = False) #2 represent the numbers of majority classes each user will have\n",
    "        user_majority_labels.append(majority_labels)\n",
    "        #label_list = list(set(label_list) - set(majority_labels))\n",
    "        #print(label_list)\n",
    "        print(i,majority_labels)\n",
    "        majority_label_idxs = (majority_labels[0] == labels[idxs])| (majority_labels[1] == labels[idxs])# |  (majority_labels[2] == labels[idxs]) | (majority_labels[3] == labels[idxs]) |  (majority_labels[4] == labels[idxs]) | (majority_labels[5] == labels[idxs]) |  (majority_labels[6] == labels[idxs]) | (majority_labels[7] == labels[idxs]) |  (majority_labels[8] == labels[idxs]) | (majority_labels[9] == labels[idxs]) |  (majority_labels[10] == labels[idxs]) | (majority_labels[11] == labels[idxs]) |  (majority_labels[12] == labels[idxs]) | (majority_labels[13] == labels[idxs]) | (majority_labels[14] == labels[idxs]) | (majority_labels[15] == labels[idxs]) |  (majority_labels[16] == labels[idxs]) | (majority_labels[17] == labels[idxs]) |  (majority_labels[18] == labels[idxs]) | (majority_labels[19] == labels[idxs]) \n",
    "        \n",
    "        sub_data_idxs = np.random.choice(idxs[majority_label_idxs], int(p*n_data), replace = False)\n",
    "        \n",
    "        dict_users[i] = np.concatenate((dict_users[i],sub_data_idxs))\n",
    "        idxs = np.array(list(set(idxs) - set(sub_data_idxs)))\n",
    "        \n",
    "        #assigning minor classes to each client\n",
    "    if(p < 1.0):\n",
    "        for i in range(num_users):\n",
    "            majority_labels = user_majority_labels[i]\n",
    "            \n",
    "            non_majority_label_idxs = (majority_labels[0] != labels[idxs]) | (majority_labels[1] != labels[idxs])# |  (majority_labels[2] != labels[idxs]) | (majority_labels[3] != labels[idxs]) |  (majority_labels[4] != labels[idxs]) | (majority_labels[5] != labels[idxs]) |  (majority_labels[6] != labels[idxs]) | (majority_labels[7] != labels[idxs]) |  (majority_labels[8] != labels[idxs]) | (majority_labels[9] != labels[idxs]) |  (majority_labels[10] != labels[idxs]) | (majority_labels[11] != labels[idxs]) |  (majority_labels[12] != labels[idxs]) | (majority_labels[13] != labels[idxs]) | (majority_labels[14] != labels[idxs]) | (majority_labels[15] != labels[idxs]) |  (majority_labels[16] != labels[idxs]) | (majority_labels[17] != labels[idxs]) |  (majority_labels[18] != labels[idxs]) | (majority_labels[19] != labels[idxs]) \n",
    "            \n",
    "            sub_data_idxs = np.random.choice(idxs[non_majority_label_idxs], int((1-p)*n_data), replace = False)\n",
    "            \n",
    "            dict_users[i] = np.concatenate((dict_users[i], sub_data_idxs))\n",
    "            idxs = np.array(list(set(idxs) - set(sub_data_idxs)))\n",
    "    idx=int((p)*n_data)\n",
    "    return dict_users,idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "qs9XZodo7FnF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [5 0]\n",
      "1 [5 2]\n",
      "2 [8 3]\n",
      "3 [4 5]\n",
      "4 [9 7]\n",
      "5 [2 9]\n",
      "6 [6 2]\n",
      "7 [0 6]\n",
      "8 [7 1]\n",
      "9 [8 3]\n",
      "10 [8 1]\n",
      "11 [6 5]\n",
      "12 [5 2]\n",
      "13 [5 2]\n",
      "14 [0 3]\n",
      "15 [8 0]\n",
      "16 [4 2]\n",
      "17 [5 2]\n",
      "18 [2 6]\n",
      "19 [5 6]\n",
      "20 [1 2]\n",
      "21 [6 2]\n",
      "22 [7 4]\n",
      "23 [3 1]\n",
      "24 [6 1]\n",
      "25 [9 7]\n",
      "26 [1 5]\n",
      "27 [5 8]\n",
      "28 [5 3]\n",
      "29 [9 0]\n",
      "30 [9 6]\n",
      "31 [6 2]\n",
      "32 [9 6]\n",
      "33 [2 4]\n",
      "34 [2 3]\n",
      "35 [6 2]\n",
      "36 [8 3]\n",
      "37 [4 5]\n",
      "38 [7 1]\n",
      "39 [9 2]\n",
      "40 [9 7]\n",
      "41 [0 2]\n",
      "42 [6 8]\n",
      "43 [6 3]\n",
      "44 [6 3]\n",
      "45 [2 0]\n",
      "46 [5 9]\n",
      "47 [0 3]\n",
      "48 [1 6]\n",
      "49 [7 4]\n"
     ]
    }
   ],
   "source": [
    "num_user=50\n",
    "p=0.7 #p is what percentage in each class, majority classs will cover the dataset\n",
    "dict_users,idx = distribute_noniid2(dataset_train,num_user,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "PQh9RRxu7Gwc"
   },
   "outputs": [],
   "source": [
    "#using image augmentation twice and add 4 transformed image\n",
    "def augment_image(dataset,idx,num_user):\n",
    "    dataset=list(dataset)\n",
    "    count=len(dataset)-1\n",
    "    final_idx=len(dict_users[0])\n",
    "    for j in range(num_user):\n",
    "        for i in dict_users[j][idx:final_idx]:\n",
    "            label=dataset[i][1]   #blurring the datatset\n",
    "            \n",
    "            img1=cv2.blur(dataset[i][0].numpy(),(2,2))\n",
    "            img1=np.transpose(img1)\n",
    "            dataset.append([img1,label])   \n",
    "            count += 1\n",
    "            dict_users[j] = np.append(dict_users[j], count)\n",
    "            \n",
    "            for k in range(4):\n",
    "                img2=transform_train_minor(dataset[i][0])  #using the trasformation technique\n",
    "                img2=np.transpose(img2.numpy())\n",
    "                dataset.append([img2,label])   \n",
    "                count += 1\n",
    "                dict_users[j] = np.append(dict_users[j], count)\n",
    "            \n",
    "    return dict_users,dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "7WJGLM6_bSkH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/ugrad/aggarwau/.local/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:876: UserWarning: Argument fill/fillcolor is not supported for Tensor input. Fill value is zero\n",
      "  warnings.warn(\"Argument fill/fillcolor is not supported for Tensor input. Fill value is zero\")\n"
     ]
    }
   ],
   "source": [
    "dict_users,dataset_train=augment_image(dataset_train,idx,num_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "h5OUsc28kyqS"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "# code to check number of images/classes\n",
    "\n",
    "samples=[]\n",
    "classes=[]\n",
    "temp=list()\n",
    "for i in dict_users[0]: \n",
    "    temp.append(dataset_train[i][1])\n",
    "for i in range(10):\n",
    "    classes.append(i) \n",
    "    samples.append(temp.count(i))\n",
    "\n",
    "mydict={'class':classes,\n",
    "           'samples':samples}\n",
    "plt.figure(figsize=(15,10))\n",
    "df=pd.DataFrame(mydict,columns=['class','samples'])\n",
    "sns.barplot(y=df['samples'],x=df['class'],data=df)\n",
    "plt.show()\n",
    "print(len(dict_users[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample 410\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code to check number of images/classes\n",
    "samples=[]\n",
    "classes=[]\n",
    "temp=list()\n",
    "for i in dict_users[0]: \n",
    "     temp.append(dataset_train[i][1])\n",
    "for i in range(10):\n",
    "    classes.append(i) \n",
    "    samples.append(temp.count(i))\n",
    "    \n",
    "mydict={'class':classes,\n",
    "       'samples':samples}\n",
    "plt.figure(figsize=(15,10))\n",
    "df=pd.DataFrame(mydict,columns=['class','samples'])\n",
    "sns.barplot(y=df['samples'],x=df['class'],data=df)\n",
    "print('total sample',len(dict_users[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "qXn3GwWhDkVX"
   },
   "outputs": [],
   "source": [
    "#checking image shape for each class, if not desired one then converting it \n",
    "dataset_train1=[]\n",
    "for i in range(len(dataset_train)):\n",
    "    temp=dataset_train[i][0]\n",
    "    if(temp.shape!=(image_size,image_size,3)):\n",
    "        temp=np.transpose(temp.numpy())\n",
    "    dataset_train1.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "eeoPFXhC7ITW"
   },
   "outputs": [],
   "source": [
    "#creating a batch data per client and binarzing the target \n",
    "lb=LabelBinarizer()\n",
    "def batch_data(data_shard):\n",
    "    bs=len(data_shard)\n",
    "    label=[]\n",
    "    img=[]\n",
    "    for i in data_shard:\n",
    "        label.append(dataset_train[i][1])\n",
    "        img.append(dataset_train1[i])    \n",
    "    label=lb.fit_transform(label)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(img),list(label)))\n",
    "    return dataset.shuffle(len(label)).batch(bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "ET_I4WH57JsY"
   },
   "outputs": [],
   "source": [
    "#process and batch the training data for each client\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in dict_users.items():\n",
    "    clients_batched[client_name] = batch_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "zWQ14gtI7K6g"
   },
   "outputs": [],
   "source": [
    "num_sample1=len(dataset_test)//2\n",
    "\n",
    "num_sample=len(dataset_test)\n",
    "#process and batch the 2test set(one for local model and one for global)\n",
    "label=[]\n",
    "data=[]\n",
    "dataset_test1=[]\n",
    "for i in range(num_sample1):\n",
    "    label.append(dataset_test[i][1])\n",
    "    temp=dataset_test[i][0].numpy()\n",
    "    image=np.transpose(temp)\n",
    "    data.append(image) \n",
    "label=lb.fit_transform(label)\n",
    "    \n",
    "test_batched_1 = tf.data.Dataset.from_tensor_slices((list(data), list(label))).batch(num_sample)\n",
    "\n",
    "label=[]\n",
    "data=[]\n",
    "dataset_test1=[]\n",
    "for i in range(num_sample1,num_sample):\n",
    "    label.append(dataset_test[i][1])\n",
    "    temp=dataset_test[i][0].numpy()\n",
    "    image=np.transpose(temp)\n",
    "    data.append(image) \n",
    "label=lb.fit_transform(label)\n",
    "    \n",
    "test_batched_2 = tf.data.Dataset.from_tensor_slices((list(data), list(label))).batch(num_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "fWEReMKb7MU4"
   },
   "outputs": [],
   "source": [
    "#building a simple NN\n",
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(classes):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(image_size,image_size,3)))\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "       # model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Flatten())       \n",
    "        model.add(Dense(500, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(classes, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam', \n",
    "                      metrics=['accuracy'])\n",
    "        #print(model.summary())\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "XmU7NRa530nP"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_test1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-752431541fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdataset_train1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdataset_test1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_test1' is not defined"
     ]
    }
   ],
   "source": [
    "del dataset_test\n",
    "del dataset_train\n",
    "del dataset_train1\n",
    "del dataset_test1\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "a3NcbmHp7RrS"
   },
   "outputs": [],
   "source": [
    "def scale_model_weights(Z,local_weight,global_weight):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(global_weight)\n",
    "    alpha=0\n",
    "    for i in range(steps):\n",
    "        w_client=np.array(local_weight[i])   #taking local weights\n",
    "        w_avg= np.array(global_weight[i])    #taking current global weights\n",
    "        l1=np.linalg.norm(w_avg-w_client)    #calculating the l1 norm\n",
    "        Z[i] = Z[i] + l1                     #updating the normalizing factor\n",
    "        alpha=l1/Z[i]                        #calculating the final alpha value\n",
    "        weight_final.append(alpha * local_weight[i])  #appending the updated weights to the scaled weight list\n",
    "    return weight_final,Z\n",
    "\n",
    "def sum_scaled_weights(scaled_list):\n",
    "    #get the IDA average grad accross all client gradients\n",
    "    avg_grad = list()\n",
    "    for grad_list_tuple in zip(*scaled_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "    return avg_grad\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    #logits = model.predict(X_test, batch_size=100)\n",
    "    logits = model.predict(X_test)\n",
    "    loss = cce(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# global_model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# global_model.load_weights(\"model.h5\")\n",
    "# print(\"Loaded model from disk\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "pCILYXJ97TUU",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "comm_round: 0 | global_acc: 11.800% | global_loss: 2.3023202419281006\n",
      "Saved model to disk\n",
      "comm_round: 1 | global_acc: 14.280% | global_loss: 2.2976598739624023\n",
      "Saved model to disk\n",
      "comm_round: 2 | global_acc: 21.620% | global_loss: 2.26842999458313\n",
      "Saved model to disk\n",
      "comm_round: 3 | global_acc: 24.160% | global_loss: 2.267639398574829\n",
      "Saved model to disk\n",
      "comm_round: 4 | global_acc: 29.680% | global_loss: 2.2307379245758057\n",
      "Saved model to disk\n",
      "comm_round: 5 | global_acc: 31.940% | global_loss: 2.233262777328491\n",
      "Saved model to disk\n",
      "comm_round: 6 | global_acc: 33.500% | global_loss: 2.195194959640503\n",
      "Saved model to disk\n",
      "comm_round: 7 | global_acc: 34.700% | global_loss: 2.1960806846618652\n",
      "Saved model to disk\n",
      "comm_round: 8 | global_acc: 36.240% | global_loss: 2.164689064025879\n",
      "Saved model to disk\n",
      "comm_round: 9 | global_acc: 37.060% | global_loss: 2.1562323570251465\n",
      "Saved model to disk\n",
      "comm_round: 10 | global_acc: 37.880% | global_loss: 2.1424505710601807\n",
      "Saved model to disk\n",
      "comm_round: 11 | global_acc: 38.240% | global_loss: 2.129030704498291\n",
      "Saved model to disk\n",
      "comm_round: 12 | global_acc: 38.540% | global_loss: 2.120976209640503\n",
      "Saved model to disk\n",
      "comm_round: 13 | global_acc: 39.320% | global_loss: 2.1097254753112793\n",
      "Saved model to disk\n",
      "comm_round: 14 | global_acc: 40.400% | global_loss: 2.1024835109710693\n",
      "Saved model to disk\n",
      "comm_round: 15 | global_acc: 40.860% | global_loss: 2.095463752746582\n",
      "Saved model to disk\n",
      "comm_round: 16 | global_acc: 41.480% | global_loss: 2.088294506072998\n",
      "Saved model to disk\n",
      "comm_round: 17 | global_acc: 41.840% | global_loss: 2.0812621116638184\n",
      "Saved model to disk\n",
      "comm_round: 18 | global_acc: 42.000% | global_loss: 2.0732922554016113\n",
      "Saved model to disk\n",
      "comm_round: 19 | global_acc: 42.460% | global_loss: 2.0680935382843018\n",
      "Saved model to disk\n",
      "comm_round: 20 | global_acc: 42.980% | global_loss: 2.061455011367798\n",
      "Saved model to disk\n",
      "comm_round: 21 | global_acc: 42.960% | global_loss: 2.059739828109741\n",
      "Saved model to disk\n",
      "comm_round: 22 | global_acc: 43.640% | global_loss: 2.0494232177734375\n",
      "Saved model to disk\n",
      "comm_round: 23 | global_acc: 43.940% | global_loss: 2.0466294288635254\n",
      "Saved model to disk\n",
      "comm_round: 24 | global_acc: 44.320% | global_loss: 2.04404616355896\n",
      "Saved model to disk\n",
      "comm_round: 25 | global_acc: 44.640% | global_loss: 2.0396130084991455\n",
      "Saved model to disk\n",
      "comm_round: 26 | global_acc: 45.020% | global_loss: 2.035618305206299\n",
      "Saved model to disk\n",
      "comm_round: 27 | global_acc: 45.240% | global_loss: 2.032806396484375\n",
      "Saved model to disk\n",
      "comm_round: 28 | global_acc: 45.360% | global_loss: 2.029794454574585\n",
      "Saved model to disk\n",
      "comm_round: 29 | global_acc: 45.800% | global_loss: 2.026860237121582\n",
      "Saved model to disk\n",
      "comm_round: 30 | global_acc: 45.980% | global_loss: 2.0258402824401855\n",
      "Saved model to disk\n",
      "comm_round: 31 | global_acc: 46.060% | global_loss: 2.0210185050964355\n",
      "Saved model to disk\n",
      "comm_round: 32 | global_acc: 46.360% | global_loss: 2.022576332092285\n",
      "Saved model to disk\n",
      "comm_round: 33 | global_acc: 46.280% | global_loss: 2.0169689655303955\n",
      "Saved model to disk\n",
      "comm_round: 34 | global_acc: 46.500% | global_loss: 2.0179049968719482\n",
      "Saved model to disk\n",
      "comm_round: 35 | global_acc: 46.800% | global_loss: 2.0134952068328857\n",
      "Saved model to disk\n",
      "comm_round: 36 | global_acc: 46.660% | global_loss: 2.0155491828918457\n",
      "Saved model to disk\n",
      "comm_round: 37 | global_acc: 46.780% | global_loss: 2.011448860168457\n",
      "Saved model to disk\n",
      "comm_round: 38 | global_acc: 46.660% | global_loss: 2.0110785961151123\n",
      "Saved model to disk\n",
      "comm_round: 39 | global_acc: 47.180% | global_loss: 2.0083558559417725\n"
     ]
    }
   ],
   "source": [
    "#initialize global model\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(10)\n",
    "\n",
    "comm_round=40\n",
    "Z=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "#commence global training loop\n",
    "for comm_round in range(comm_round):     \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "\n",
    "    #initial list to collect local model weights after scalling\n",
    "    local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(10)\n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "      #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=2, verbose=0,validation_data=test_batched_1)\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaled_weights,Z = scale_model_weights(Z,local_model.get_weights(),global_model.get_weights())\n",
    "        local_weight_list.append(scaled_weights)\n",
    "       \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights= sum_scaled_weights(local_weight_list)\n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "    \n",
    "    model_json = global_model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        \n",
    "# serialize weights to HDF5\n",
    "    global_model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched_2:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mnist_non_iid (1).ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
